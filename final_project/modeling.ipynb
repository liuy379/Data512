{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas.tseries.holiday import USFederalHolidayCalendar as calendar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/allen/Documents/data_512/Data/call_data_filtered.csv')\n",
    "\n",
    "df['Original Time Queued'] = pd.to_datetime(df['Original Time Queued'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['Call_Hour'] = ds['Original Time Queued'].dt.hour\n",
    "ds['Call_Weekday'] = ds['Original Time Queued'].dt.weekday\n",
    "\n",
    "ds['Call_Hour_Bin'] = ds['Call_Hour'].apply(utils.create_hour_bin)\n",
    "\n",
    "\n",
    "# extract holiday info\n",
    "cal = calendar()\n",
    "holidays = cal.holidays(start=ds['Original Time Queued'].min(), end=ds['Original Time Queued'].max())\n",
    "ds['is_Holiday'] = ds['Original Time Queued'].dt.date.isin(pd.Series(holidays).dt.date).astype(int)\n",
    "\n",
    "# encoding\n",
    "ds = ds[['Call Type','Priority','Precinct','Sector','response_time','Call_Weekday','Call_Hour_Bin','is_Holiday']]\n",
    "\n",
    "ds = pd.get_dummies(ds, \n",
    "               columns=['Call Type','Priority','Precinct','Sector','Call_Weekday','Call_Hour_Bin'],\n",
    "               prefix=['Call Type','Priority','Precinct','Sector','Call_Weekday','Call_Hour_Bin'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(ds.drop(columns=['response_time']),\n",
    "                                                  ds['response_time'],\n",
    "                                                  test_size=0.2, \n",
    "                                                  random_state=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "                      max_features='auto', max_leaf_nodes=None,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=1, min_samples_split=2,\n",
       "                      min_weight_fraction_leaf=0.0, n_estimators=20,\n",
       "                      n_jobs=None, oob_score=False, random_state=10, verbose=0,\n",
       "                      warm_start=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_reg = RandomForestRegressor(n_estimators=20, random_state=10, criterion='rmse',\n",
    "                                  min_samples_leaf=10)\n",
    "forest_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_forest = forest_reg.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7745.610398011465"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.sqrt(sum((y_val - pred_forest)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_grid = [{'max_depth': [10, 20, 30],\n",
    "#                'min_samples_leaf': [1, 2, 4],\n",
    "#                'min_samples_split': [2, 5, 10],\n",
    "#                'n_estimators': [100, 200, 400]}]\n",
    "\n",
    "# forest_clf = RandomForestRegressor(n_estimators=20, random_state=10)\n",
    "\n",
    "# grid_search_full = GridSearchCV(forest_clf, param_grid, cv=3, verbose=3, n_jobs=-1)\n",
    "# grid_search_full.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dval = xgb.DMatrix(X_val, label=y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "    'objective': 'reg:squarederror',\n",
    "    'eva_metric': 'rmse',\n",
    "    'eta': 0.03,\n",
    "    'subsample': 0.8,\n",
    "    'colsample': 0.8,\n",
    "    'max_depth': 6\n",
    "}\n",
    "\n",
    "num_round = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:43:31] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[0]\teval-rmse:21.1554\ttrain-rmse:21.0545\n",
      "Multiple eval metrics have been passed: 'train-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until train-rmse hasn't improved in 10 rounds.\n",
      "[1]\teval-rmse:20.775\ttrain-rmse:20.6748\n",
      "[2]\teval-rmse:20.4102\ttrain-rmse:20.3105\n",
      "[3]\teval-rmse:20.0606\ttrain-rmse:19.9623\n",
      "[4]\teval-rmse:19.7267\ttrain-rmse:19.628\n",
      "[5]\teval-rmse:19.4067\ttrain-rmse:19.3076\n",
      "[6]\teval-rmse:19.1008\ttrain-rmse:19.0016\n",
      "[7]\teval-rmse:18.808\ttrain-rmse:18.7085\n",
      "[8]\teval-rmse:18.5287\ttrain-rmse:18.4291\n",
      "[9]\teval-rmse:18.2619\ttrain-rmse:18.1628\n",
      "[10]\teval-rmse:18.0072\ttrain-rmse:17.9082\n",
      "[11]\teval-rmse:17.7638\ttrain-rmse:17.6651\n",
      "[12]\teval-rmse:17.5323\ttrain-rmse:17.4336\n",
      "[13]\teval-rmse:17.311\ttrain-rmse:17.2131\n",
      "[14]\teval-rmse:17.1002\ttrain-rmse:17.0029\n",
      "[15]\teval-rmse:16.8995\ttrain-rmse:16.8028\n",
      "[16]\teval-rmse:16.7082\ttrain-rmse:16.612\n",
      "[17]\teval-rmse:16.5262\ttrain-rmse:16.4312\n",
      "[18]\teval-rmse:16.3532\ttrain-rmse:16.2586\n",
      "[19]\teval-rmse:16.1886\ttrain-rmse:16.0943\n",
      "[20]\teval-rmse:16.0322\ttrain-rmse:15.9389\n",
      "[21]\teval-rmse:15.8832\ttrain-rmse:15.7911\n",
      "[22]\teval-rmse:15.7421\ttrain-rmse:15.6508\n",
      "[23]\teval-rmse:15.6078\ttrain-rmse:15.5172\n",
      "[24]\teval-rmse:15.4802\ttrain-rmse:15.3905\n",
      "[25]\teval-rmse:15.3592\ttrain-rmse:15.2705\n",
      "[26]\teval-rmse:15.2447\ttrain-rmse:15.1569\n",
      "[27]\teval-rmse:15.1357\ttrain-rmse:15.0489\n",
      "[28]\teval-rmse:15.0326\ttrain-rmse:14.9466\n",
      "[29]\teval-rmse:14.9347\ttrain-rmse:14.8496\n",
      "[30]\teval-rmse:14.8421\ttrain-rmse:14.7579\n",
      "[31]\teval-rmse:14.7542\ttrain-rmse:14.6709\n",
      "[32]\teval-rmse:14.671\ttrain-rmse:14.5886\n",
      "[33]\teval-rmse:14.5921\ttrain-rmse:14.5106\n",
      "[34]\teval-rmse:14.5175\ttrain-rmse:14.437\n",
      "[35]\teval-rmse:14.4466\ttrain-rmse:14.367\n",
      "[36]\teval-rmse:14.3798\ttrain-rmse:14.3008\n",
      "[37]\teval-rmse:14.3164\ttrain-rmse:14.2384\n",
      "[38]\teval-rmse:14.2565\ttrain-rmse:14.1793\n",
      "[39]\teval-rmse:14.1997\ttrain-rmse:14.1234\n",
      "[40]\teval-rmse:14.1463\ttrain-rmse:14.0707\n",
      "[41]\teval-rmse:14.0957\ttrain-rmse:14.0206\n",
      "[42]\teval-rmse:14.048\ttrain-rmse:13.9735\n",
      "[43]\teval-rmse:14.0029\ttrain-rmse:13.9289\n",
      "[44]\teval-rmse:13.9602\ttrain-rmse:13.8868\n",
      "[45]\teval-rmse:13.9198\ttrain-rmse:13.8469\n",
      "[46]\teval-rmse:13.8815\ttrain-rmse:13.8092\n",
      "[47]\teval-rmse:13.8455\ttrain-rmse:13.7737\n",
      "[48]\teval-rmse:13.8115\ttrain-rmse:13.7404\n",
      "[49]\teval-rmse:13.7795\ttrain-rmse:13.7088\n",
      "[50]\teval-rmse:13.749\ttrain-rmse:13.6787\n",
      "[51]\teval-rmse:13.7202\ttrain-rmse:13.6507\n",
      "[52]\teval-rmse:13.6933\ttrain-rmse:13.6241\n",
      "[53]\teval-rmse:13.6674\ttrain-rmse:13.5991\n",
      "[54]\teval-rmse:13.6434\ttrain-rmse:13.5754\n",
      "[55]\teval-rmse:13.6206\ttrain-rmse:13.553\n",
      "[56]\teval-rmse:13.5991\ttrain-rmse:13.5318\n",
      "[57]\teval-rmse:13.5788\ttrain-rmse:13.512\n",
      "[58]\teval-rmse:13.5595\ttrain-rmse:13.4934\n",
      "[59]\teval-rmse:13.5413\ttrain-rmse:13.4755\n",
      "[60]\teval-rmse:13.5243\ttrain-rmse:13.4588\n",
      "[61]\teval-rmse:13.5081\ttrain-rmse:13.4429\n",
      "[62]\teval-rmse:13.4926\ttrain-rmse:13.4279\n",
      "[63]\teval-rmse:13.4782\ttrain-rmse:13.4138\n",
      "[64]\teval-rmse:13.4645\ttrain-rmse:13.4007\n",
      "[65]\teval-rmse:13.4516\ttrain-rmse:13.3881\n",
      "[66]\teval-rmse:13.4395\ttrain-rmse:13.3762\n",
      "[67]\teval-rmse:13.4281\ttrain-rmse:13.3651\n",
      "[68]\teval-rmse:13.4173\ttrain-rmse:13.3546\n",
      "[69]\teval-rmse:13.4071\ttrain-rmse:13.3447\n",
      "[70]\teval-rmse:13.3974\ttrain-rmse:13.3353\n",
      "[71]\teval-rmse:13.3883\ttrain-rmse:13.3264\n",
      "[72]\teval-rmse:13.3795\ttrain-rmse:13.3179\n",
      "[73]\teval-rmse:13.3711\ttrain-rmse:13.31\n",
      "[74]\teval-rmse:13.3633\ttrain-rmse:13.3024\n",
      "[75]\teval-rmse:13.3559\ttrain-rmse:13.2952\n",
      "[76]\teval-rmse:13.349\ttrain-rmse:13.2884\n",
      "[77]\teval-rmse:13.3424\ttrain-rmse:13.2823\n",
      "[78]\teval-rmse:13.3364\ttrain-rmse:13.2764\n",
      "[79]\teval-rmse:13.3306\ttrain-rmse:13.2708\n",
      "[80]\teval-rmse:13.325\ttrain-rmse:13.2657\n",
      "[81]\teval-rmse:13.3199\ttrain-rmse:13.2605\n",
      "[82]\teval-rmse:13.3149\ttrain-rmse:13.2558\n",
      "[83]\teval-rmse:13.3103\ttrain-rmse:13.2514\n",
      "[84]\teval-rmse:13.3059\ttrain-rmse:13.2473\n",
      "[85]\teval-rmse:13.3018\ttrain-rmse:13.2432\n",
      "[86]\teval-rmse:13.2978\ttrain-rmse:13.2393\n",
      "[87]\teval-rmse:13.2941\ttrain-rmse:13.2359\n",
      "[88]\teval-rmse:13.2906\ttrain-rmse:13.2325\n",
      "[89]\teval-rmse:13.2873\ttrain-rmse:13.2293\n",
      "[90]\teval-rmse:13.284\ttrain-rmse:13.2263\n",
      "[91]\teval-rmse:13.281\ttrain-rmse:13.2234\n",
      "[92]\teval-rmse:13.2782\ttrain-rmse:13.2206\n",
      "[93]\teval-rmse:13.2756\ttrain-rmse:13.2182\n",
      "[94]\teval-rmse:13.273\ttrain-rmse:13.2156\n",
      "[95]\teval-rmse:13.2704\ttrain-rmse:13.2132\n",
      "[96]\teval-rmse:13.2681\ttrain-rmse:13.2111\n",
      "[97]\teval-rmse:13.2659\ttrain-rmse:13.2089\n",
      "[98]\teval-rmse:13.264\ttrain-rmse:13.2071\n",
      "[99]\teval-rmse:13.262\ttrain-rmse:13.2053\n",
      "[100]\teval-rmse:13.2601\ttrain-rmse:13.2034\n",
      "[101]\teval-rmse:13.258\ttrain-rmse:13.2015\n",
      "[102]\teval-rmse:13.2563\ttrain-rmse:13.1997\n",
      "[103]\teval-rmse:13.2544\ttrain-rmse:13.1981\n",
      "[104]\teval-rmse:13.2528\ttrain-rmse:13.1964\n",
      "[105]\teval-rmse:13.2513\ttrain-rmse:13.195\n",
      "[106]\teval-rmse:13.25\ttrain-rmse:13.1936\n",
      "[107]\teval-rmse:13.2485\ttrain-rmse:13.1922\n",
      "[108]\teval-rmse:13.2472\ttrain-rmse:13.191\n",
      "[109]\teval-rmse:13.246\ttrain-rmse:13.19\n",
      "[110]\teval-rmse:13.2448\ttrain-rmse:13.1889\n",
      "[111]\teval-rmse:13.2438\ttrain-rmse:13.188\n",
      "[112]\teval-rmse:13.2427\ttrain-rmse:13.1867\n",
      "[113]\teval-rmse:13.2415\ttrain-rmse:13.1857\n",
      "[114]\teval-rmse:13.2406\ttrain-rmse:13.1848\n",
      "[115]\teval-rmse:13.2395\ttrain-rmse:13.1838\n",
      "[116]\teval-rmse:13.2387\ttrain-rmse:13.1829\n",
      "[117]\teval-rmse:13.2377\ttrain-rmse:13.182\n",
      "[118]\teval-rmse:13.2368\ttrain-rmse:13.1811\n",
      "[119]\teval-rmse:13.236\ttrain-rmse:13.1802\n",
      "[120]\teval-rmse:13.2354\ttrain-rmse:13.1795\n",
      "[121]\teval-rmse:13.2346\ttrain-rmse:13.1788\n",
      "[122]\teval-rmse:13.2339\ttrain-rmse:13.1781\n",
      "[123]\teval-rmse:13.2333\ttrain-rmse:13.1775\n",
      "[124]\teval-rmse:13.2325\ttrain-rmse:13.1768\n",
      "[125]\teval-rmse:13.232\ttrain-rmse:13.1763\n",
      "[126]\teval-rmse:13.2315\ttrain-rmse:13.1758\n",
      "[127]\teval-rmse:13.2309\ttrain-rmse:13.1752\n",
      "[128]\teval-rmse:13.2303\ttrain-rmse:13.1746\n",
      "[129]\teval-rmse:13.2298\ttrain-rmse:13.1741\n",
      "[130]\teval-rmse:13.2293\ttrain-rmse:13.1735\n",
      "[131]\teval-rmse:13.2287\ttrain-rmse:13.1729\n",
      "[132]\teval-rmse:13.2282\ttrain-rmse:13.1724\n",
      "[133]\teval-rmse:13.2277\ttrain-rmse:13.172\n",
      "[134]\teval-rmse:13.2272\ttrain-rmse:13.1714\n",
      "[135]\teval-rmse:13.2268\ttrain-rmse:13.171\n",
      "[136]\teval-rmse:13.2265\ttrain-rmse:13.1707\n",
      "[137]\teval-rmse:13.2261\ttrain-rmse:13.1703\n",
      "[138]\teval-rmse:13.2258\ttrain-rmse:13.1698\n",
      "[139]\teval-rmse:13.2255\ttrain-rmse:13.1695\n",
      "[140]\teval-rmse:13.2251\ttrain-rmse:13.1691\n",
      "[141]\teval-rmse:13.2248\ttrain-rmse:13.1688\n",
      "[142]\teval-rmse:13.2245\ttrain-rmse:13.1685\n",
      "[143]\teval-rmse:13.2242\ttrain-rmse:13.1681\n",
      "[144]\teval-rmse:13.2239\ttrain-rmse:13.1678\n",
      "[145]\teval-rmse:13.2236\ttrain-rmse:13.1674\n",
      "[146]\teval-rmse:13.2233\ttrain-rmse:13.1671\n",
      "[147]\teval-rmse:13.223\ttrain-rmse:13.1669\n",
      "[148]\teval-rmse:13.2227\ttrain-rmse:13.1666\n",
      "[149]\teval-rmse:13.2225\ttrain-rmse:13.1663\n",
      "[150]\teval-rmse:13.2221\ttrain-rmse:13.1659\n",
      "[151]\teval-rmse:13.2219\ttrain-rmse:13.1656\n",
      "[152]\teval-rmse:13.2216\ttrain-rmse:13.1654\n",
      "[153]\teval-rmse:13.2214\ttrain-rmse:13.1652\n",
      "[154]\teval-rmse:13.2213\ttrain-rmse:13.1649\n",
      "[155]\teval-rmse:13.2211\ttrain-rmse:13.1647\n",
      "[156]\teval-rmse:13.2209\ttrain-rmse:13.1644\n",
      "[157]\teval-rmse:13.2208\ttrain-rmse:13.1643\n",
      "[158]\teval-rmse:13.2206\ttrain-rmse:13.164\n",
      "[159]\teval-rmse:13.2204\ttrain-rmse:13.1637\n",
      "[160]\teval-rmse:13.2201\ttrain-rmse:13.1634\n",
      "[161]\teval-rmse:13.22\ttrain-rmse:13.1632\n",
      "[162]\teval-rmse:13.2197\ttrain-rmse:13.163\n",
      "[163]\teval-rmse:13.2196\ttrain-rmse:13.1628\n",
      "[164]\teval-rmse:13.2194\ttrain-rmse:13.1625\n",
      "[165]\teval-rmse:13.2192\ttrain-rmse:13.1624\n",
      "[166]\teval-rmse:13.219\ttrain-rmse:13.1621\n",
      "[167]\teval-rmse:13.2189\ttrain-rmse:13.162\n",
      "[168]\teval-rmse:13.2187\ttrain-rmse:13.1618\n",
      "[169]\teval-rmse:13.2186\ttrain-rmse:13.1616\n",
      "[170]\teval-rmse:13.2184\ttrain-rmse:13.1613\n",
      "[171]\teval-rmse:13.2182\ttrain-rmse:13.1611\n",
      "[172]\teval-rmse:13.218\ttrain-rmse:13.161\n",
      "[173]\teval-rmse:13.2179\ttrain-rmse:13.1608\n",
      "[174]\teval-rmse:13.2177\ttrain-rmse:13.1606\n",
      "[175]\teval-rmse:13.2176\ttrain-rmse:13.1604\n",
      "[176]\teval-rmse:13.2175\ttrain-rmse:13.1603\n",
      "[177]\teval-rmse:13.2173\ttrain-rmse:13.1602\n",
      "[178]\teval-rmse:13.2172\ttrain-rmse:13.16\n",
      "[179]\teval-rmse:13.2171\ttrain-rmse:13.1598\n",
      "[180]\teval-rmse:13.217\ttrain-rmse:13.1597\n",
      "[181]\teval-rmse:13.2169\ttrain-rmse:13.1596\n",
      "[182]\teval-rmse:13.2168\ttrain-rmse:13.1594\n",
      "[183]\teval-rmse:13.2166\ttrain-rmse:13.1592\n",
      "[184]\teval-rmse:13.2164\ttrain-rmse:13.159\n",
      "[185]\teval-rmse:13.2163\ttrain-rmse:13.1589\n",
      "[186]\teval-rmse:13.2162\ttrain-rmse:13.1587\n",
      "[187]\teval-rmse:13.2161\ttrain-rmse:13.1585\n",
      "[188]\teval-rmse:13.216\ttrain-rmse:13.1583\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[189]\teval-rmse:13.2159\ttrain-rmse:13.1581\n",
      "[190]\teval-rmse:13.2158\ttrain-rmse:13.158\n",
      "[191]\teval-rmse:13.2157\ttrain-rmse:13.1579\n",
      "[192]\teval-rmse:13.2156\ttrain-rmse:13.1577\n",
      "[193]\teval-rmse:13.2156\ttrain-rmse:13.1577\n",
      "[194]\teval-rmse:13.2155\ttrain-rmse:13.1575\n",
      "[195]\teval-rmse:13.2154\ttrain-rmse:13.1574\n",
      "[196]\teval-rmse:13.2153\ttrain-rmse:13.1573\n",
      "[197]\teval-rmse:13.2152\ttrain-rmse:13.1572\n",
      "[198]\teval-rmse:13.2151\ttrain-rmse:13.1571\n",
      "[199]\teval-rmse:13.215\ttrain-rmse:13.157\n",
      "[200]\teval-rmse:13.2149\ttrain-rmse:13.1568\n",
      "[201]\teval-rmse:13.2148\ttrain-rmse:13.1567\n",
      "[202]\teval-rmse:13.2147\ttrain-rmse:13.1566\n",
      "[203]\teval-rmse:13.2146\ttrain-rmse:13.1565\n",
      "[204]\teval-rmse:13.2146\ttrain-rmse:13.1563\n",
      "[205]\teval-rmse:13.2145\ttrain-rmse:13.1562\n",
      "[206]\teval-rmse:13.2145\ttrain-rmse:13.156\n",
      "[207]\teval-rmse:13.2144\ttrain-rmse:13.1559\n",
      "[208]\teval-rmse:13.2143\ttrain-rmse:13.1559\n",
      "[209]\teval-rmse:13.2142\ttrain-rmse:13.1557\n",
      "[210]\teval-rmse:13.2142\ttrain-rmse:13.1555\n",
      "[211]\teval-rmse:13.2141\ttrain-rmse:13.1555\n",
      "[212]\teval-rmse:13.214\ttrain-rmse:13.1554\n",
      "[213]\teval-rmse:13.2139\ttrain-rmse:13.1552\n",
      "[214]\teval-rmse:13.2138\ttrain-rmse:13.1551\n",
      "[215]\teval-rmse:13.2138\ttrain-rmse:13.155\n",
      "[216]\teval-rmse:13.2137\ttrain-rmse:13.1549\n",
      "[217]\teval-rmse:13.2137\ttrain-rmse:13.1548\n",
      "[218]\teval-rmse:13.2136\ttrain-rmse:13.1547\n",
      "[219]\teval-rmse:13.2135\ttrain-rmse:13.1546\n",
      "[220]\teval-rmse:13.2135\ttrain-rmse:13.1545\n",
      "[221]\teval-rmse:13.2134\ttrain-rmse:13.1543\n",
      "[222]\teval-rmse:13.2133\ttrain-rmse:13.1542\n",
      "[223]\teval-rmse:13.2133\ttrain-rmse:13.1541\n",
      "[224]\teval-rmse:13.2132\ttrain-rmse:13.1541\n",
      "[225]\teval-rmse:13.2131\ttrain-rmse:13.1539\n",
      "[226]\teval-rmse:13.213\ttrain-rmse:13.1538\n",
      "[227]\teval-rmse:13.213\ttrain-rmse:13.1537\n",
      "[228]\teval-rmse:13.2129\ttrain-rmse:13.1535\n",
      "[229]\teval-rmse:13.2129\ttrain-rmse:13.1535\n",
      "[230]\teval-rmse:13.2128\ttrain-rmse:13.1534\n",
      "[231]\teval-rmse:13.2128\ttrain-rmse:13.1533\n",
      "[232]\teval-rmse:13.2127\ttrain-rmse:13.1532\n",
      "[233]\teval-rmse:13.2126\ttrain-rmse:13.1531\n",
      "[234]\teval-rmse:13.2126\ttrain-rmse:13.153\n",
      "[235]\teval-rmse:13.2125\ttrain-rmse:13.1529\n",
      "[236]\teval-rmse:13.2124\ttrain-rmse:13.1528\n",
      "[237]\teval-rmse:13.2124\ttrain-rmse:13.1527\n",
      "[238]\teval-rmse:13.2123\ttrain-rmse:13.1525\n",
      "[239]\teval-rmse:13.2122\ttrain-rmse:13.1525\n",
      "[240]\teval-rmse:13.2122\ttrain-rmse:13.1523\n",
      "[241]\teval-rmse:13.2122\ttrain-rmse:13.1523\n",
      "[242]\teval-rmse:13.2121\ttrain-rmse:13.1522\n",
      "[243]\teval-rmse:13.2121\ttrain-rmse:13.1521\n",
      "[244]\teval-rmse:13.212\ttrain-rmse:13.152\n",
      "[245]\teval-rmse:13.212\ttrain-rmse:13.1519\n",
      "[246]\teval-rmse:13.2119\ttrain-rmse:13.1517\n",
      "[247]\teval-rmse:13.2119\ttrain-rmse:13.1517\n",
      "[248]\teval-rmse:13.2118\ttrain-rmse:13.1515\n",
      "[249]\teval-rmse:13.2117\ttrain-rmse:13.1515\n",
      "[250]\teval-rmse:13.2117\ttrain-rmse:13.1514\n",
      "[251]\teval-rmse:13.2117\ttrain-rmse:13.1513\n",
      "[252]\teval-rmse:13.2116\ttrain-rmse:13.1512\n",
      "[253]\teval-rmse:13.2116\ttrain-rmse:13.1511\n",
      "[254]\teval-rmse:13.2116\ttrain-rmse:13.151\n",
      "[255]\teval-rmse:13.2116\ttrain-rmse:13.1509\n",
      "[256]\teval-rmse:13.2115\ttrain-rmse:13.1508\n",
      "[257]\teval-rmse:13.2114\ttrain-rmse:13.1507\n",
      "[258]\teval-rmse:13.2114\ttrain-rmse:13.1507\n",
      "[259]\teval-rmse:13.2113\ttrain-rmse:13.1506\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-9360dc2dd27a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m                 \u001b[0mnum_round\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                 \u001b[0mwatchlist\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                 early_stopping_rounds=10)\n\u001b[0m",
      "\u001b[0;32m/anaconda3/envs/env_0/lib/python3.7/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[1;32m    214\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/env_0/lib/python3.7/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/env_0/lib/python3.7/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1107\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, ctypes.c_int(iteration),\n\u001b[0;32m-> 1109\u001b[0;31m                                                     dtrain.handle))\n\u001b[0m\u001b[1;32m   1110\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# specify validations set to watch performance\n",
    "watchlist = [(dval, 'eval'), (dtrain, 'train')]\n",
    "bst = xgb.train(param, \n",
    "                dtrain, \n",
    "                num_round,\n",
    "                watchlist,\n",
    "                early_stopping_rounds=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
